import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Sample data
X = np.asarray([20, 5, 10, 13, 12])
Y = np.asarray([44, 22, 25, 32, 27])

# Initialize the model parameters
b1 = 0
b0 = 0

L = 0.001  # The learning rate
epochs = 1000  # The number of iterations to perform gradient descent
n = np.size(X)  # Number of elements in X

# Performing Gradient Descent
for i in range(epochs):
    Total_Err_x, Total_Err_y = 0, 0
    for x, y in zip(X, Y):
        y_pred = b1 * x + b0  # The current predicted value of y
        err = y - y_pred
        Total_Err_x += x * err  # Update for b1
        Total_Err_y += err      # Update for b0

    D_b1 = (-2 / n) * Total_Err_x  # Derivative wrt b1
    D_b0 = (-2 / n) * Total_Err_y  # Derivative wrt b0
    b1 = b1 - L * D_b1  # Update b1
    b0 = b0 - L * D_b0  # Update b0

# Print final values of b1 and b0
print("b1:", b1, "b0:", b0)

# Making predictions
Y_pred = b1 * X + b0

# Mean Squared Error (MSE)
MSE = mean_squared_error(Y, Y_pred)
print('MSE: %f' % MSE)

# Coefficient of Determination (R^2 Score)
coefficient_of_determination = r2_score(Y, Y_pred)
print('Coefficient of Determination (R^2): %f' % coefficient_of_determination)

# Plotting the results
plt.figure(figsize=(10, 5))
plt.scatter(X, Y, label='Actual Data')  # Scatter plot for actual data
plt.plot(X, Y_pred, 'r', linewidth=2, label='Fitted Line')  # Plot for predicted line
plt.xlabel('X values')
plt.ylabel('Y values')
plt.title('Linear Regression Using Gradient Descent')
plt.legend()
plt.show()
